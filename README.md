# üö¶ Predicci√≥n de Severidad de Accidentes de Tr√°fico en Madrid

## üìã Descripci√≥n del Proyecto

Este proyecto de **Data Science** aborda un problema de **clasificaci√≥n supervisada** para predecir la severidad (lesividad) de accidentes de tr√°fico ocurridos en Madrid.  
La severidad se agrupa en dos categor√≠as:  

- üî¥ **GRAVE:** Accidentes que requieren asistencia sanitaria.  
- üü¢ **LEVE:** Accidentes que no requieren asistencia sanitaria.  

El objetivo es desarrollar un modelo predictivo que, a partir de variables como las condiciones meteorol√≥gicas, la hora del accidente y el consumo de alcohol y drogas, permita clasificar correctamente la severidad del accidente.

**Fuente de datos**:  
[Portal de Datos Abiertos del Ayuntamiento de Madrid](https://datos.madrid.es/portal/site/egob/menuitem.c05c1f754a33a9fbe4b2e4b284f1a5a0/?vgnextchannel=374512b9ace9f310VgnVCM100000171f5a0aRCRD&vgnextfmt=default&vgnextoid=7c2843010d9c3610VgnVCM2000001f4a900aRCRD&utm_source=chatgpt.com)

---

## üìÇ Estructura del Proyecto

El proyecto est√° organizado en las siguientes secciones principales:

### 1Ô∏è‚É£ Metadata y Preparaci√≥n de Datos  
- Carga y descripci√≥n del dataset original.  
- Limpieza y tratamiento de datos faltantes o err√≥neos.  
- Ingenier√≠a de atributos: transformaci√≥n de la variable objetivo en dos clases (GRAVE / LEVE), codificaci√≥n de variables categ√≥ricas y normalizaci√≥n si es necesario.

### 2Ô∏è‚É£ An√°lisis Exploratorio de Datos (EDA)  
- An√°lisis estad√≠stico descriptivo.  
- Visualizaci√≥n de la distribuci√≥n de variables y relaciones entre ellas.  
- Identificaci√≥n de patrones y posibles insights preliminares.

### 3Ô∏è‚É£ Entrenamiento y Evaluaci√≥n Inicial  
- Divisi√≥n del dataset en entrenamiento (70%) y testeo (30%).  
- Entrenamiento y evaluaci√≥n de tres modelos supervisados:  
  - üå≥ √Årbol de Decisi√≥n  
  - üå≤ Random Forest  
  - ‚ö° XGBoost  
- Evaluaci√≥n con m√©tricas como accuracy, matriz de confusi√≥n, precisi√≥n, recall y F1-score.

### 4Ô∏è‚É£ Selecci√≥n del Mejor Modelo  
- Comparaci√≥n de resultados entre modelos.  
- Selecci√≥n de **Random Forest** por su desempe√±o equilibrado y estabilidad.

### 5Ô∏è‚É£ Validaci√≥n Cruzada y M√©tricas Finales  
- Aplicaci√≥n de validaci√≥n cruzada (K-Fold y LOOCV) sobre Random Forest para evaluar robustez y evitar overfitting.  
- C√°lculo de m√©tricas promedio y curva ROC AUC para medir capacidad discriminativa.

### 6Ô∏è‚É£ Optimizaci√≥n de Hiperpar√°metros  
- Uso de Grid Search y Randomized Search para encontrar la mejor combinaci√≥n de hiperpar√°metros en Random Forest y XGBoost.  
- Mejora en el desempe√±o gracias a la optimizaci√≥n.

### 7Ô∏è‚É£ Modelo de Ensamble con Boosting  
- Implementaci√≥n y evaluaci√≥n del modelo XGBoost como m√©todo de ensamble.  
- Comparativa con Random Forest para valorar su efectividad en la clasificaci√≥n.

---

## üìä Resultados

- La precisi√≥n final alcanzada con el mejor modelo (Random Forest optimizado) supera el **63%**.  
- La validaci√≥n cruzada confirma la estabilidad del modelo y su capacidad para generalizar.  
- El modelo de ensamble (**XGBoost**) mostr√≥ una mejora interesante tras la optimizaci√≥n de hiperpar√°metros.

---

M. Mercedes Agustin
